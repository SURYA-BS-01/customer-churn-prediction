{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3_i4KlhI-rj"
      },
      "source": [
        "## Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1voH6ywQJCw4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LlWTMi6I4Ec"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"data/Telco_customer_churn.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si23tFLoqSLi",
        "outputId": "fb542ecb-2925-4e42-a0b5-d8588296998b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Total Charges'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G2wlcs9xqnzw"
      },
      "outputs": [],
      "source": [
        "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5AZls4-Kvo4Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SURYA B.S\\AppData\\Local\\Temp\\ipykernel_17068\\2269432574.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Total Charges'].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df['Total Charges'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomerID              0\n",
              "Count                   0\n",
              "Country                 0\n",
              "State                   0\n",
              "City                    0\n",
              "Zip Code                0\n",
              "Lat Long                0\n",
              "Latitude                0\n",
              "Longitude               0\n",
              "Gender                  0\n",
              "Senior Citizen          0\n",
              "Partner                 0\n",
              "Dependents              0\n",
              "Tenure Months           0\n",
              "Phone Service           0\n",
              "Multiple Lines          0\n",
              "Internet Service        0\n",
              "Online Security         0\n",
              "Online Backup           0\n",
              "Device Protection       0\n",
              "Tech Support            0\n",
              "Streaming TV            0\n",
              "Streaming Movies        0\n",
              "Contract                0\n",
              "Paperless Billing       0\n",
              "Payment Method          0\n",
              "Monthly Charges         0\n",
              "Total Charges           0\n",
              "Churn Label             0\n",
              "Churn Value             0\n",
              "Churn Score             0\n",
              "CLTV                    0\n",
              "Churn Reason         5174\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGDV3GjWnrDc"
      },
      "source": [
        "## Preparing data for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlw5GCZbxEkd"
      },
      "source": [
        "### Encoding Categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-30CN3yoDYo",
        "outputId": "c45fd248-506b-4c67-bf79-fe1a9533afdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Competitor made better offer', 'Moved',\n",
              "       'Competitor had better devices',\n",
              "       'Competitor offered higher download speeds',\n",
              "       'Competitor offered more data', 'Price too high',\n",
              "       'Product dissatisfaction', 'Service dissatisfaction',\n",
              "       'Lack of self-service on Website', 'Network reliability',\n",
              "       'Limited range of services',\n",
              "       'Lack of affordable download/upload speed',\n",
              "       'Long distance charges', 'Extra data charges', \"Don't know\",\n",
              "       'Poor expertise of online support',\n",
              "       'Poor expertise of phone support', 'Attitude of service provider',\n",
              "       'Attitude of support person', 'Deceased', nan], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Churn Reason'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KlcpdJEXnyht"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"Country\", \"State\", \"Count\", \"Zip Code\",\n",
        "              \"Churn Reason\", \"City\", \"Churn Value\",\n",
        "              \"Churn Score\", \"CLTV\", \"CustomerID\", \"Latitude\",\n",
        "              \"Longitude\", \"Lat Long\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akE9kC8gp6cR",
        "outputId": "04144a5c-d423-4804-f569-517fcf159187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 20 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Gender             7043 non-null   object \n",
            " 1   Senior Citizen     7043 non-null   object \n",
            " 2   Partner            7043 non-null   object \n",
            " 3   Dependents         7043 non-null   object \n",
            " 4   Tenure Months      7043 non-null   int64  \n",
            " 5   Phone Service      7043 non-null   object \n",
            " 6   Multiple Lines     7043 non-null   object \n",
            " 7   Internet Service   7043 non-null   object \n",
            " 8   Online Security    7043 non-null   object \n",
            " 9   Online Backup      7043 non-null   object \n",
            " 10  Device Protection  7043 non-null   object \n",
            " 11  Tech Support       7043 non-null   object \n",
            " 12  Streaming TV       7043 non-null   object \n",
            " 13  Streaming Movies   7043 non-null   object \n",
            " 14  Contract           7043 non-null   object \n",
            " 15  Paperless Billing  7043 non-null   object \n",
            " 16  Payment Method     7043 non-null   object \n",
            " 17  Monthly Charges    7043 non-null   float64\n",
            " 18  Total Charges      7043 non-null   float64\n",
            " 19  Churn Label        7043 non-null   object \n",
            "dtypes: float64(2), int64(1), object(17)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
            "C:\\Users\\SURYA B.S\\AppData\\Local\\Temp\\ipykernel_17068\\3674382906.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df.to_csv(\".\\data\\modified_data.csv\", index=False, header=True)\n"
          ]
        }
      ],
      "source": [
        "df.to_csv(\".\\data\\modified_data.csv\", index=False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "numerical_columns = ['Tenure Months', 'Monthly Charges', 'Total Charges']\n",
        "categorical_columns = [\n",
        "    'Gender',\n",
        "    'Senior Citizen',\n",
        "    'Partner',\n",
        "    'Dependents',\n",
        "    'Phone Service',\n",
        "    'Multiple Lines',\n",
        "    'Internet Service',\n",
        "    'Online Security',\n",
        "    'Online Backup',\n",
        "    'Device Protection',\n",
        "    'Tech Support',\n",
        "    'Streaming TV',\n",
        "    'Streaming Movies',\n",
        "    'Contract',\n",
        "    'Paperless Billing',\n",
        "    'Payment Method',\n",
        "]\n",
        "\n",
        "num_pipeline = Pipeline(\n",
        "    steps= [(\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "get_dummies_transformer = FunctionTransformer(lambda df: pd.get_dummies(df, columns=categorical_columns, drop_first=True), validate=False)\n",
        "\n",
        "cat_pipeline = Pipeline(\n",
        "    steps= [(\"get_dummies\", get_dummies_transformer)]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"num_pipeline\", num_pipeline, numerical_columns),\n",
        "        (\"cat_pipeline\", cat_pipeline, categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_df = preprocessor.fit_transform(train_df)\n",
        "test_df = preprocessor.transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.570886</td>\n",
              "      <td>1.133166</td>\n",
              "      <td>2.070847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.669405</td>\n",
              "      <td>0.952708</td>\n",
              "      <td>-0.310095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.017684</td>\n",
              "      <td>1.311969</td>\n",
              "      <td>0.504214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.343545</td>\n",
              "      <td>-0.787308</td>\n",
              "      <td>-0.593026</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.506475</td>\n",
              "      <td>-1.469407</td>\n",
              "      <td>-0.825967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>1.367223</td>\n",
              "      <td>1.340113</td>\n",
              "      <td>2.039302</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>-0.547207</td>\n",
              "      <td>0.714304</td>\n",
              "      <td>-0.328320</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>-1.239661</td>\n",
              "      <td>0.858340</td>\n",
              "      <td>-0.921197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1.448688</td>\n",
              "      <td>1.515605</td>\n",
              "      <td>2.293803</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1408</th>\n",
              "      <td>-0.099149</td>\n",
              "      <td>1.167933</td>\n",
              "      <td>0.305623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7043 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2    3    4    5    6    7    8    9    10  \\\n",
              "0     1.570886  1.133166  2.070847  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
              "1    -0.669405  0.952708 -0.310095  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "2    -0.017684  1.311969  0.504214  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "3    -0.343545 -0.787308 -0.593026  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
              "4    -0.506475 -1.469407 -0.825967  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0   \n",
              "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "1404  1.367223  1.340113  2.039302  0.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0   \n",
              "1405 -0.547207  0.714304 -0.328320  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "1406 -1.239661  0.858340 -0.921197  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
              "1407  1.448688  1.515605  2.293803  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0   \n",
              "1408 -0.099149  1.167933  0.305623  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "\n",
              "       11   12   13   14   15   16   17   18   19   20   21   22   23   24  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "1     0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
              "4     1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "1404  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
              "1405  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
              "1406  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
              "1407  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
              "1408  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
              "\n",
              "       25   26   27   28  \n",
              "0     0.0  1.0  1.0  0.0  \n",
              "1     0.0  1.0  1.0  0.0  \n",
              "2     0.0  1.0  1.0  0.0  \n",
              "3     0.0  1.0  1.0  0.0  \n",
              "4     0.0  0.0  0.0  0.0  \n",
              "...   ...  ...  ...  ...  \n",
              "1404  0.0  1.0  0.0  1.0  \n",
              "1405  0.0  1.0  0.0  0.0  \n",
              "1406  0.0  0.0  0.0  1.0  \n",
              "1407  1.0  1.0  0.0  1.0  \n",
              "1408  0.0  1.0  0.0  1.0  \n",
              "\n",
              "[7043 rows x 29 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.DataFrame(train_df)\n",
        "test_df = pd.DataFrame(test_df)\n",
        "X = pd.concat([train_df.iloc[:, :-1], test_df.iloc[:, :-1]])\n",
        "y = pd.concat([train_df.iloc[:, -1], test_df.iloc[:, -1]])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZrhUjfS35Pp"
      },
      "source": [
        "## Building a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score, make_scorer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"XGBClassifier\": XGBClassifier(),\n",
        "    \"CatBoosting Classifier\": CatBoostClassifier(silent=True),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
        "    \"LightGBM Classifier\": LGBMClassifier()\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"Decision Tree\": {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'splitter': ['best', 'random'],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'n_estimators': [50, 100, 200, 300, 400, 500]\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        'loss': ['log_loss', 'exponential'],\n",
        "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
        "        'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9],\n",
        "        'criterion': ['friedman_mse', 'squared_error'],\n",
        "        'max_features': ['sqrt', 'log2'],\n",
        "        'n_estimators': [50, 100, 200, 300, 400, 500]\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "        'C': [0.01, 0.1, 1.0, 10, 100],\n",
        "        'solver': ['liblinear', 'saga']\n",
        "    },\n",
        "    \"XGBClassifier\": {\n",
        "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
        "        'n_estimators': [50, 100, 200, 300, 400, 500],\n",
        "        'max_depth': [3, 4, 5, 6, 7, 8]\n",
        "    },\n",
        "    \"CatBoosting Classifier\": {\n",
        "        'depth': [6, 8, 10],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'iterations': [100, 200, 300, 500]\n",
        "    },\n",
        "    \"AdaBoost Classifier\": {\n",
        "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
        "        'n_estimators': [50, 100, 200, 300, 400, 500]\n",
        "    },\n",
        "    \"LightGBM Classifier\": {\n",
        "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
        "        'n_estimators': [50, 100, 200, 300, 400, 500],\n",
        "        'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "        'num_leaves': [20, 30, 40, 50, 60]\n",
        "    }\n",
        "}\n",
        "\n",
        "def evaluate_models(X_train, y_train, X_test, y_test, models, params):\n",
        "    report = {}\n",
        "    for model_name, model in models.items():\n",
        "        param_grid = params[model_name]\n",
        "\n",
        "        # Define the Stratified K-Fold Cross-Validator\n",
        "        stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        # Define the F1 scorer\n",
        "        f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "        rs = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=stratified_kfold, scoring=f1_scorer)\n",
        "\n",
        "        rs.fit(X_train, y_train)\n",
        "\n",
        "        # Get the best parameters and best F1 score\n",
        "        best_params = rs.best_params_\n",
        "        best_score = rs.best_score_\n",
        "\n",
        "        # Get the best model with best parameters\n",
        "        best_model = rs.best_estimator_\n",
        "\n",
        "        # Train the best model on the full training data\n",
        "        best_model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the testing data\n",
        "        y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "        # Check if the model supports probability estimation\n",
        "        if hasattr(best_model, \"predict_proba\"):\n",
        "            y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "            roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "        else:\n",
        "            roc_auc = None\n",
        "\n",
        "        # Calculate metrics\n",
        "        classification_rep = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "        precision = classification_rep['weighted avg']['precision']\n",
        "        recall = classification_rep['weighted avg']['recall']\n",
        "        f1 = classification_rep['weighted avg']['f1-score']\n",
        "\n",
        "        # Store the results\n",
        "        report[model_name] = {\n",
        "            'best_params': best_params,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'roc_auc': roc_auc\n",
        "        }\n",
        "\n",
        "    return report\n",
        "\n",
        "results = evaluate_models(X_train, y_train, X_test, y_test, models, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Decision Tree\n",
            "Best Parameters: {'splitter': 'random', 'max_features': None, 'criterion': 'entropy'}\n",
            "Precision: 0.8174598150884864\n",
            "Recall: 0.8173913043478261\n",
            "F1 Score: 0.8173331228475444\n",
            "ROC AUC: 0.8167646440828333\n",
            "\n",
            "Model: Random Forest\n",
            "Best Parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'criterion': 'gini'}\n",
            "Precision: 0.8686479277556288\n",
            "Recall: 0.8685990338164251\n",
            "F1 Score: 0.8685715369096128\n",
            "ROC AUC: 0.9312492704223378\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 400, 'max_features': 'log2', 'loss': 'log_loss', 'learning_rate': 0.1, 'criterion': 'friedman_mse'}\n",
            "Precision: 0.8604584993145062\n",
            "Recall: 0.8603864734299517\n",
            "F1 Score: 0.8603499185486647\n",
            "ROC AUC: 0.9382999089487076\n",
            "\n",
            "Model: Logistic Regression\n",
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.1}\n",
            "Precision: 0.7885211298254777\n",
            "Recall: 0.7879227053140097\n",
            "F1 Score: 0.787663552774533\n",
            "ROC AUC: 0.8702201573553102\n",
            "\n",
            "Model: XGBClassifier\n",
            "Best Parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05}\n",
            "Precision: 0.8682159358825221\n",
            "Recall: 0.8681159420289855\n",
            "F1 Score: 0.8680764801241548\n",
            "ROC AUC: 0.9407802395349381\n",
            "\n",
            "Model: CatBoosting Classifier\n",
            "Best Parameters: {'learning_rate': 0.05, 'iterations': 500, 'depth': 10}\n",
            "Precision: 0.8763550081457399\n",
            "Recall: 0.8763285024154589\n",
            "F1 Score: 0.87633439188633\n",
            "ROC AUC: 0.9461676744566104\n",
            "\n",
            "Model: AdaBoost Classifier\n",
            "Best Parameters: {'n_estimators': 50, 'learning_rate': 0.1}\n",
            "Precision: 0.8111102529592673\n",
            "Recall: 0.8077294685990338\n",
            "F1 Score: 0.8069373175327398\n",
            "ROC AUC: 0.8801779002171224\n",
            "\n",
            "Model: LightGBM Classifier\n",
            "Best Parameters: {'num_leaves': 40, 'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.05}\n",
            "Precision: 0.8642470338092054\n",
            "Recall: 0.8642512077294686\n",
            "F1 Score: 0.8642440761932316\n",
            "ROC AUC: 0.9418485746970793\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model_name, result in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Best Parameters: {result['best_params']}\")\n",
        "    print(f\"Precision: {result['precision']}\")\n",
        "    print(f\"Recall: {result['recall']}\")\n",
        "    print(f\"F1 Score: {result['f1_score']}\")\n",
        "    if result['roc_auc'] is not None:\n",
        "        print(f\"ROC AUC: {result['roc_auc']}\")\n",
        "    else:\n",
        "        print(\"ROC AUC: Not available\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Best model here is CatBoostClassifier.\n",
        "\n",
        "Let's further tune it with optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YJjWiTiw2rYv"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cCBFXl_HzoHJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, f1_score\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  params = {\n",
        "      \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
        "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "      \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
        "      \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
        "      \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "      \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
        "      \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "      \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
        "      \"od_wait\": trial.suggest_int(\"od_wait\", 10, 50),\n",
        "  }\n",
        "\n",
        "  model = CatBoostClassifier(**params, silent=True)\n",
        "  score = cross_val_score(model, X_train, y_train, cv=5, scoring=f1_scorer, n_jobs=-1).mean()\n",
        "\n",
        "  return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-05-13 03:45:52,257] A new study created in memory with name: no-name-3943ef1d-531d-4248-b60d-3ecea49ed5ae\n",
            "[I 2024-05-13 03:45:58,035] Trial 0 finished with value: 0.8578381132070954 and parameters: {'iterations': 167, 'learning_rate': 0.04332696373973052, 'depth': 5, 'l2_leaf_reg': 0.08112808125475827, 'subsample': 0.9341198133703117, 'colsample_bylevel': 0.6997474360191243, 'min_data_in_leaf': 71, 'od_type': 'IncToDec', 'od_wait': 39}. Best is trial 0 with value: 0.8578381132070954.\n",
            "[I 2024-05-13 03:47:06,453] Trial 1 finished with value: 0.8652786000590282 and parameters: {'iterations': 925, 'learning_rate': 0.01015164492512863, 'depth': 10, 'l2_leaf_reg': 0.5429528604183685, 'subsample': 0.45332974395447967, 'colsample_bylevel': 0.24187016653766225, 'min_data_in_leaf': 13, 'od_type': 'Iter', 'od_wait': 33}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:47:14,059] Trial 2 finished with value: 0.8596473652231067 and parameters: {'iterations': 449, 'learning_rate': 0.054780207677662535, 'depth': 5, 'l2_leaf_reg': 0.0061292153083186635, 'subsample': 0.9465519913281975, 'colsample_bylevel': 0.14439331611210518, 'min_data_in_leaf': 77, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:47:18,830] Trial 3 finished with value: 0.8142630372892917 and parameters: {'iterations': 272, 'learning_rate': 0.007691446425111642, 'depth': 4, 'l2_leaf_reg': 86.41790292280933, 'subsample': 0.6059158584820877, 'colsample_bylevel': 0.6940902836270798, 'min_data_in_leaf': 20, 'od_type': 'Iter', 'od_wait': 49}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:47:24,063] Trial 4 finished with value: 0.8329976567298484 and parameters: {'iterations': 610, 'learning_rate': 0.030195368720826444, 'depth': 5, 'l2_leaf_reg': 61.81050262881831, 'subsample': 0.27947131345601306, 'colsample_bylevel': 0.05282206892810523, 'min_data_in_leaf': 27, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:47:50,101] Trial 5 finished with value: 0.8216497547759134 and parameters: {'iterations': 991, 'learning_rate': 0.001842613992799379, 'depth': 7, 'l2_leaf_reg': 8.045598415835943, 'subsample': 0.6432765364320104, 'colsample_bylevel': 0.22590003529128988, 'min_data_in_leaf': 7, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:48:02,347] Trial 6 finished with value: 0.8607422855314478 and parameters: {'iterations': 685, 'learning_rate': 0.037831911208720335, 'depth': 5, 'l2_leaf_reg': 6.05442318771384e-05, 'subsample': 0.8960528607941814, 'colsample_bylevel': 0.24531788945023542, 'min_data_in_leaf': 1, 'od_type': 'IncToDec', 'od_wait': 23}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:49:11,519] Trial 7 finished with value: 0.8641252962916617 and parameters: {'iterations': 920, 'learning_rate': 0.023840711503919976, 'depth': 8, 'l2_leaf_reg': 0.0009321380692135509, 'subsample': 0.5352324938374369, 'colsample_bylevel': 0.6962221937166714, 'min_data_in_leaf': 14, 'od_type': 'Iter', 'od_wait': 23}. Best is trial 1 with value: 0.8652786000590282.\n",
            "[I 2024-05-13 03:50:08,824] Trial 8 finished with value: 0.86903834014648 and parameters: {'iterations': 543, 'learning_rate': 0.026497429964508955, 'depth': 9, 'l2_leaf_reg': 8.120730004260338e-07, 'subsample': 0.3188758781655129, 'colsample_bylevel': 0.39686387373698245, 'min_data_in_leaf': 94, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 8 with value: 0.86903834014648.\n",
            "[I 2024-05-13 03:50:29,796] Trial 9 finished with value: 0.8283758006193223 and parameters: {'iterations': 121, 'learning_rate': 0.0019933417322604797, 'depth': 9, 'l2_leaf_reg': 0.00016148862356571298, 'subsample': 0.9770319388148115, 'colsample_bylevel': 0.9212267127260059, 'min_data_in_leaf': 58, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 8 with value: 0.86903834014648.\n",
            "[I 2024-05-13 03:50:43,620] Trial 10 finished with value: 0.8562437462133314 and parameters: {'iterations': 474, 'learning_rate': 0.009084151442706582, 'depth': 7, 'l2_leaf_reg': 6.735403925847685e-08, 'subsample': 0.1499068791057996, 'colsample_bylevel': 0.4237805542394913, 'min_data_in_leaf': 96, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 8 with value: 0.86903834014648.\n",
            "[I 2024-05-13 03:52:07,077] Trial 11 finished with value: 0.8688304782874994 and parameters: {'iterations': 796, 'learning_rate': 0.005030638356681353, 'depth': 10, 'l2_leaf_reg': 5.505295166571578e-08, 'subsample': 0.32192001900008904, 'colsample_bylevel': 0.4117550783071352, 'min_data_in_leaf': 39, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 8 with value: 0.86903834014648.\n",
            "[I 2024-05-13 03:53:30,123] Trial 12 finished with value: 0.867695099042427 and parameters: {'iterations': 746, 'learning_rate': 0.004277819478737608, 'depth': 10, 'l2_leaf_reg': 1.0332281227639221e-08, 'subsample': 0.3512036777736035, 'colsample_bylevel': 0.46055598179208895, 'min_data_in_leaf': 40, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 8 with value: 0.86903834014648.\n",
            "[I 2024-05-13 03:54:53,052] Trial 13 finished with value: 0.8696551954203056 and parameters: {'iterations': 808, 'learning_rate': 0.015989487360132514, 'depth': 9, 'l2_leaf_reg': 1.1465668937578366e-06, 'subsample': 0.05920683277696015, 'colsample_bylevel': 0.37669554466928945, 'min_data_in_leaf': 99, 'od_type': 'Iter', 'od_wait': 39}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 03:55:20,850] Trial 14 finished with value: 0.8618959846230478 and parameters: {'iterations': 397, 'learning_rate': 0.017518383045033527, 'depth': 8, 'l2_leaf_reg': 3.6027115892207023e-06, 'subsample': 0.07653847604333806, 'colsample_bylevel': 0.5824975775497251, 'min_data_in_leaf': 96, 'od_type': 'Iter', 'od_wait': 41}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 03:56:21,390] Trial 15 finished with value: 0.8603289823717072 and parameters: {'iterations': 588, 'learning_rate': 0.09707682635597208, 'depth': 9, 'l2_leaf_reg': 3.254364732043987e-06, 'subsample': 0.17405997054013989, 'colsample_bylevel': 0.3650569544524484, 'min_data_in_leaf': 83, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 03:57:16,093] Trial 16 finished with value: 0.865862766654371 and parameters: {'iterations': 823, 'learning_rate': 0.016090588726737673, 'depth': 8, 'l2_leaf_reg': 1.8735651587902216e-06, 'subsample': 0.06270811971026394, 'colsample_bylevel': 0.5681752885523882, 'min_data_in_leaf': 100, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 03:58:17,882] Trial 17 finished with value: 0.8617578080504021 and parameters: {'iterations': 695, 'learning_rate': 0.07316676321640729, 'depth': 9, 'l2_leaf_reg': 2.635561249006303e-07, 'subsample': 0.20136573742773453, 'colsample_bylevel': 0.29769646943371936, 'min_data_in_leaf': 62, 'od_type': 'Iter', 'od_wait': 27}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 03:58:26,430] Trial 18 finished with value: 0.8589938825277968 and parameters: {'iterations': 331, 'learning_rate': 0.017879482088723656, 'depth': 6, 'l2_leaf_reg': 1.937966737528818e-05, 'subsample': 0.7491061674467552, 'colsample_bylevel': 0.5242730200791799, 'min_data_in_leaf': 86, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 04:00:04,704] Trial 19 finished with value: 0.865429630556528 and parameters: {'iterations': 556, 'learning_rate': 0.005063293627130326, 'depth': 9, 'l2_leaf_reg': 5.136746169882333e-07, 'subsample': 0.41655663658393144, 'colsample_bylevel': 0.9202094284533824, 'min_data_in_leaf': 87, 'od_type': 'Iter', 'od_wait': 42}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 04:00:47,376] Trial 20 finished with value: 0.8321349163759748 and parameters: {'iterations': 846, 'learning_rate': 0.0012013596904291279, 'depth': 8, 'l2_leaf_reg': 0.0015963166648696834, 'subsample': 0.24692702549915574, 'colsample_bylevel': 0.33017428234691737, 'min_data_in_leaf': 67, 'od_type': 'Iter', 'od_wait': 37}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 04:02:08,550] Trial 21 finished with value: 0.86736940205348 and parameters: {'iterations': 795, 'learning_rate': 0.003941724649310726, 'depth': 10, 'l2_leaf_reg': 2.2084066835646107e-08, 'subsample': 0.3258537077939863, 'colsample_bylevel': 0.4088978676846329, 'min_data_in_leaf': 39, 'od_type': 'Iter', 'od_wait': 29}. Best is trial 13 with value: 0.8696551954203056.\n",
            "[I 2024-05-13 04:03:27,592] Trial 22 finished with value: 0.8703234653660138 and parameters: {'iterations': 675, 'learning_rate': 0.011864123857221541, 'depth': 10, 'l2_leaf_reg': 1.4283138542574344e-07, 'subsample': 0.41230891162115835, 'colsample_bylevel': 0.49496562686875145, 'min_data_in_leaf': 50, 'od_type': 'Iter', 'od_wait': 31}. Best is trial 22 with value: 0.8703234653660138.\n",
            "[I 2024-05-13 04:04:54,116] Trial 23 finished with value: 0.8686213109706408 and parameters: {'iterations': 697, 'learning_rate': 0.012592898422701507, 'depth': 9, 'l2_leaf_reg': 1.2066780812624229e-05, 'subsample': 0.42689116632277646, 'colsample_bylevel': 0.5152134871436982, 'min_data_in_leaf': 50, 'od_type': 'Iter', 'od_wait': 35}. Best is trial 22 with value: 0.8703234653660138.\n",
            "[I 2024-05-13 04:06:24,587] Trial 24 finished with value: 0.8713208857919413 and parameters: {'iterations': 621, 'learning_rate': 0.024353378281919903, 'depth': 10, 'l2_leaf_reg': 3.1643167923503056e-07, 'subsample': 0.5161932597076504, 'colsample_bylevel': 0.6305212782846544, 'min_data_in_leaf': 52, 'od_type': 'Iter', 'od_wait': 46}. Best is trial 24 with value: 0.8713208857919413.\n",
            "[I 2024-05-13 04:08:16,116] Trial 25 finished with value: 0.8720809064194445 and parameters: {'iterations': 630, 'learning_rate': 0.012800687249354861, 'depth': 10, 'l2_leaf_reg': 1.4461217177681586e-07, 'subsample': 0.7632841028296689, 'colsample_bylevel': 0.818306891734643, 'min_data_in_leaf': 53, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 25 with value: 0.8720809064194445.\n",
            "[I 2024-05-13 04:10:10,772] Trial 26 finished with value: 0.8726005704544118 and parameters: {'iterations': 629, 'learning_rate': 0.00621922172248774, 'depth': 10, 'l2_leaf_reg': 1.273969780656737e-07, 'subsample': 0.7914311705515797, 'colsample_bylevel': 0.8292217799388937, 'min_data_in_leaf': 49, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:11:36,392] Trial 27 finished with value: 0.8710331258314538 and parameters: {'iterations': 486, 'learning_rate': 0.0068379372808898276, 'depth': 10, 'l2_leaf_reg': 1.1081231681191578e-08, 'subsample': 0.8060394369583973, 'colsample_bylevel': 0.8163510222732664, 'min_data_in_leaf': 56, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:13:25,840] Trial 28 finished with value: 0.8609446974905994 and parameters: {'iterations': 622, 'learning_rate': 0.002607822005563946, 'depth': 10, 'l2_leaf_reg': 1.844763782716747e-07, 'subsample': 0.7386167082247951, 'colsample_bylevel': 0.8151169982406763, 'min_data_in_leaf': 46, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:13:44,742] Trial 29 finished with value: 0.859862924785036 and parameters: {'iterations': 513, 'learning_rate': 0.04876840988327107, 'depth': 6, 'l2_leaf_reg': 0.04377748435026223, 'subsample': 0.8658661532899178, 'colsample_bylevel': 0.9894930837363751, 'min_data_in_leaf': 32, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:15:32,997] Trial 30 finished with value: 0.8722592999094438 and parameters: {'iterations': 642, 'learning_rate': 0.006427163329828959, 'depth': 10, 'l2_leaf_reg': 1.018993764592264e-05, 'subsample': 0.6624210830221771, 'colsample_bylevel': 0.7653549928178308, 'min_data_in_leaf': 72, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:17:25,130] Trial 31 finished with value: 0.8708456408904081 and parameters: {'iterations': 637, 'learning_rate': 0.006472031454123886, 'depth': 10, 'l2_leaf_reg': 4.834877262957084e-06, 'subsample': 0.6555277231241035, 'colsample_bylevel': 0.7799194568899384, 'min_data_in_leaf': 70, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:19:08,399] Trial 32 finished with value: 0.8638257534211314 and parameters: {'iterations': 741, 'learning_rate': 0.0030698411273438597, 'depth': 10, 'l2_leaf_reg': 9.384684618660268e-05, 'subsample': 0.5320319251702471, 'colsample_bylevel': 0.6250626392083736, 'min_data_in_leaf': 64, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 26 with value: 0.8726005704544118.\n",
            "[I 2024-05-13 04:20:18,309] Trial 33 finished with value: 0.8730550345763101 and parameters: {'iterations': 416, 'learning_rate': 0.010080115124293045, 'depth': 10, 'l2_leaf_reg': 5.891643166350359e-08, 'subsample': 0.7200841770994407, 'colsample_bylevel': 0.7575398175873095, 'min_data_in_leaf': 75, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:21:27,936] Trial 34 finished with value: 0.8663580153795458 and parameters: {'iterations': 409, 'learning_rate': 0.010222683477600922, 'depth': 9, 'l2_leaf_reg': 6.025895476765706e-08, 'subsample': 0.7214726657096301, 'colsample_bylevel': 0.7667368357952674, 'min_data_in_leaf': 78, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:22:18,013] Trial 35 finished with value: 0.8658759240663108 and parameters: {'iterations': 268, 'learning_rate': 0.00859193462510973, 'depth': 10, 'l2_leaf_reg': 1.789900556655768e-05, 'subsample': 0.8213700130611711, 'colsample_bylevel': 0.879345350400369, 'min_data_in_leaf': 75, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:22:26,458] Trial 36 finished with value: 0.8368565608586362 and parameters: {'iterations': 388, 'learning_rate': 0.0060357675992223315, 'depth': 4, 'l2_leaf_reg': 4.8080582404182495e-08, 'subsample': 0.6773352661721401, 'colsample_bylevel': 0.7470677636586703, 'min_data_in_leaf': 74, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:22:45,417] Trial 37 finished with value: 0.8353976675216606 and parameters: {'iterations': 260, 'learning_rate': 0.0032319626751515277, 'depth': 8, 'l2_leaf_reg': 0.00039483890489208325, 'subsample': 0.5935202783185352, 'colsample_bylevel': 0.8659907951461616, 'min_data_in_leaf': 58, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:24:03,813] Trial 38 finished with value: 0.8596481908559905 and parameters: {'iterations': 533, 'learning_rate': 0.012887543689495677, 'depth': 9, 'l2_leaf_reg': 0.6700400945333204, 'subsample': 0.8229819184151139, 'colsample_bylevel': 0.9896889584470886, 'min_data_in_leaf': 30, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:25:14,553] Trial 39 finished with value: 0.8661317426235307 and parameters: {'iterations': 442, 'learning_rate': 0.0075726904127904485, 'depth': 10, 'l2_leaf_reg': 0.007357660094285234, 'subsample': 0.9180586160082758, 'colsample_bylevel': 0.6692217860120927, 'min_data_in_leaf': 44, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:25:28,680] Trial 40 finished with value: 0.8575320177219163 and parameters: {'iterations': 338, 'learning_rate': 0.010935859354637546, 'depth': 7, 'l2_leaf_reg': 4.677693473816638e-05, 'subsample': 0.5862229998812909, 'colsample_bylevel': 0.7343092740337934, 'min_data_in_leaf': 81, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:26:51,066] Trial 41 finished with value: 0.8707393769200976 and parameters: {'iterations': 572, 'learning_rate': 0.02354687740871346, 'depth': 10, 'l2_leaf_reg': 3.182656066361809e-07, 'subsample': 0.4767457784593989, 'colsample_bylevel': 0.6430234731858785, 'min_data_in_leaf': 54, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:28:51,940] Trial 42 finished with value: 0.8633488393606031 and parameters: {'iterations': 655, 'learning_rate': 0.03617282504377697, 'depth': 10, 'l2_leaf_reg': 8.345010311535108e-07, 'subsample': 0.7644851375822475, 'colsample_bylevel': 0.8418666389831035, 'min_data_in_leaf': 63, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:30:48,388] Trial 43 finished with value: 0.8667320248838213 and parameters: {'iterations': 733, 'learning_rate': 0.024339891784477343, 'depth': 9, 'l2_leaf_reg': 1.22675404586422e-07, 'subsample': 0.6994100217470381, 'colsample_bylevel': 0.7184240512143695, 'min_data_in_leaf': 46, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:32:48,924] Trial 44 finished with value: 0.869589484314163 and parameters: {'iterations': 609, 'learning_rate': 0.019353731369968367, 'depth': 10, 'l2_leaf_reg': 2.3618358395191333e-08, 'subsample': 0.626245810658068, 'colsample_bylevel': 0.9202230725021218, 'min_data_in_leaf': 70, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:34:06,910] Trial 45 finished with value: 0.8701361111774867 and parameters: {'iterations': 513, 'learning_rate': 0.03363364668673415, 'depth': 10, 'l2_leaf_reg': 4.7158260420868474e-07, 'subsample': 0.565966862734521, 'colsample_bylevel': 0.6882987497033292, 'min_data_in_leaf': 90, 'od_type': 'IncToDec', 'od_wait': 38}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:35:42,510] Trial 46 finished with value: 0.8691234007652515 and parameters: {'iterations': 587, 'learning_rate': 0.008720896946399038, 'depth': 9, 'l2_leaf_reg': 8.075231039361538e-06, 'subsample': 0.4808576231673914, 'colsample_bylevel': 0.79104187118163, 'min_data_in_leaf': 35, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:36:10,524] Trial 47 finished with value: 0.8655359898681508 and parameters: {'iterations': 201, 'learning_rate': 0.013771305153577287, 'depth': 10, 'l2_leaf_reg': 1.374812885806774e-06, 'subsample': 0.766118294370984, 'colsample_bylevel': 0.5971649445034413, 'min_data_in_leaf': 54, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:38:48,094] Trial 48 finished with value: 0.8691887219031393 and parameters: {'iterations': 891, 'learning_rate': 0.005240564988540977, 'depth': 9, 'l2_leaf_reg': 2.3658039398258892e-08, 'subsample': 0.6705482183679975, 'colsample_bylevel': 0.8818460368316587, 'min_data_in_leaf': 18, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:40:45,243] Trial 49 finished with value: 0.8681202044966762 and parameters: {'iterations': 719, 'learning_rate': 0.029541436940373533, 'depth': 10, 'l2_leaf_reg': 8.773799514568645e-08, 'subsample': 0.8648099956331371, 'colsample_bylevel': 0.7133188610714615, 'min_data_in_leaf': 25, 'od_type': 'Iter', 'od_wait': 34}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:41:51,857] Trial 50 finished with value: 0.8581684291377887 and parameters: {'iterations': 457, 'learning_rate': 0.004312752589805304, 'depth': 9, 'l2_leaf_reg': 1.8556196788678072e-06, 'subsample': 0.8040339143589201, 'colsample_bylevel': 0.633899063349916, 'min_data_in_leaf': 60, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:43:20,457] Trial 51 finished with value: 0.8688107976763785 and parameters: {'iterations': 503, 'learning_rate': 0.006584643874548302, 'depth': 10, 'l2_leaf_reg': 1.1237796394862577e-08, 'subsample': 0.77672701713956, 'colsample_bylevel': 0.8068274729567243, 'min_data_in_leaf': 52, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:44:47,584] Trial 52 finished with value: 0.8716398640801873 and parameters: {'iterations': 475, 'learning_rate': 0.007325321175507329, 'depth': 10, 'l2_leaf_reg': 1.1281347564913611e-08, 'subsample': 0.9950905216670407, 'colsample_bylevel': 0.8242455147865656, 'min_data_in_leaf': 43, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 33 with value: 0.8730550345763101.\n",
            "[I 2024-05-13 04:46:58,642] Trial 53 finished with value: 0.8734575834740295 and parameters: {'iterations': 652, 'learning_rate': 0.009770604858673523, 'depth': 10, 'l2_leaf_reg': 3.664194974785296e-08, 'subsample': 0.9600919640675593, 'colsample_bylevel': 0.9528230790708087, 'min_data_in_leaf': 43, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:49:00,389] Trial 54 finished with value: 0.8718398563414758 and parameters: {'iterations': 666, 'learning_rate': 0.008071705287165519, 'depth': 9, 'l2_leaf_reg': 3.887684546751087e-08, 'subsample': 0.9891506819207664, 'colsample_bylevel': 0.943573933221664, 'min_data_in_leaf': 42, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:49:58,496] Trial 55 finished with value: 0.8642575543125293 and parameters: {'iterations': 774, 'learning_rate': 0.009567065507047213, 'depth': 8, 'l2_leaf_reg': 4.880837842938695e-08, 'subsample': 0.8840219455990258, 'colsample_bylevel': 0.9558718327526571, 'min_data_in_leaf': 36, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:51:54,130] Trial 56 finished with value: 0.8667036913635092 and parameters: {'iterations': 653, 'learning_rate': 0.005440606411328927, 'depth': 9, 'l2_leaf_reg': 1.600083300988268e-07, 'subsample': 0.9549675596175883, 'colsample_bylevel': 0.9565429050894075, 'min_data_in_leaf': 48, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:52:18,220] Trial 57 finished with value: 0.860232291839244 and parameters: {'iterations': 673, 'learning_rate': 0.015515438645812837, 'depth': 6, 'l2_leaf_reg': 5.512653472350101e-07, 'subsample': 0.9401109258558698, 'colsample_bylevel': 0.8538885387950492, 'min_data_in_leaf': 41, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:53:55,397] Trial 58 finished with value: 0.868944572322419 and parameters: {'iterations': 543, 'learning_rate': 0.010756114518479087, 'depth': 9, 'l2_leaf_reg': 3.685532372003424e-08, 'subsample': 0.8468738645220247, 'colsample_bylevel': 0.9001500749829178, 'min_data_in_leaf': 66, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:56:30,298] Trial 59 finished with value: 0.8707785240392318 and parameters: {'iterations': 770, 'learning_rate': 0.008490333121037206, 'depth': 10, 'l2_leaf_reg': 2.9459686346274725e-06, 'subsample': 0.9173498119675721, 'colsample_bylevel': 0.9272310585443803, 'min_data_in_leaf': 35, 'od_type': 'IncToDec', 'od_wait': 11}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 04:58:51,590] Trial 60 finished with value: 0.8700148901636512 and parameters: {'iterations': 697, 'learning_rate': 0.02019347820013917, 'depth': 10, 'l2_leaf_reg': 9.72877985898302e-08, 'subsample': 0.974210384471181, 'colsample_bylevel': 0.9509504165726647, 'min_data_in_leaf': 28, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:00:10,261] Trial 61 finished with value: 0.8676940926598723 and parameters: {'iterations': 427, 'learning_rate': 0.00746277941335594, 'depth': 10, 'l2_leaf_reg': 1.0467630323575734e-08, 'subsample': 0.9591002338762503, 'colsample_bylevel': 0.8230880489488613, 'min_data_in_leaf': 42, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:00:25,214] Trial 62 finished with value: 0.8505294303386343 and parameters: {'iterations': 360, 'learning_rate': 0.00442269976548768, 'depth': 10, 'l2_leaf_reg': 2.432113538907433e-08, 'subsample': 0.9008294551467216, 'colsample_bylevel': 0.1398481174663324, 'min_data_in_leaf': 24, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:02:10,232] Trial 63 finished with value: 0.8708295632181166 and parameters: {'iterations': 597, 'learning_rate': 0.007444250869474916, 'depth': 10, 'l2_leaf_reg': 2.0494376304421112e-07, 'subsample': 0.982588911375527, 'colsample_bylevel': 0.7711348170363519, 'min_data_in_leaf': 38, 'od_type': 'IncToDec', 'od_wait': 19}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:03:46,075] Trial 64 finished with value: 0.8486059057851177 and parameters: {'iterations': 560, 'learning_rate': 0.013743711576394799, 'depth': 9, 'l2_leaf_reg': 35.809121691440524, 'subsample': 0.986143304807282, 'colsample_bylevel': 0.8332681792372102, 'min_data_in_leaf': 44, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:06:51,628] Trial 65 finished with value: 0.8715106760061214 and parameters: {'iterations': 987, 'learning_rate': 0.005459070221675895, 'depth': 10, 'l2_leaf_reg': 8.271352724330549e-08, 'subsample': 0.7178111619096812, 'colsample_bylevel': 0.9019670046347421, 'min_data_in_leaf': 48, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:08:38,644] Trial 66 finished with value: 0.8730445529052012 and parameters: {'iterations': 643, 'learning_rate': 0.009601024206172946, 'depth': 10, 'l2_leaf_reg': 2.0656777208059104e-08, 'subsample': 0.992500574181439, 'colsample_bylevel': 0.7417851597629871, 'min_data_in_leaf': 57, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:10:30,816] Trial 67 finished with value: 0.8694480325436608 and parameters: {'iterations': 651, 'learning_rate': 0.011457583031424365, 'depth': 9, 'l2_leaf_reg': 7.016027069892178e-07, 'subsample': 0.8463364962905566, 'colsample_bylevel': 0.8614844241586018, 'min_data_in_leaf': 58, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:12:14,811] Trial 68 finished with value: 0.8662275204425349 and parameters: {'iterations': 618, 'learning_rate': 0.003718289559663299, 'depth': 10, 'l2_leaf_reg': 3.426372573014212e-08, 'subsample': 0.6282358304178585, 'colsample_bylevel': 0.7544554241219725, 'min_data_in_leaf': 72, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:13:54,484] Trial 69 finished with value: 0.8683742090437715 and parameters: {'iterations': 706, 'learning_rate': 0.006125719523693387, 'depth': 9, 'l2_leaf_reg': 2.861071868175023e-07, 'subsample': 0.9241000735157209, 'colsample_bylevel': 0.993356009733462, 'min_data_in_leaf': 61, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:15:53,099] Trial 70 finished with value: 0.8731157337226103 and parameters: {'iterations': 677, 'learning_rate': 0.015322231342831606, 'depth': 10, 'l2_leaf_reg': 3.8953335227260066e-05, 'subsample': 0.7005423775586789, 'colsample_bylevel': 0.790375655866263, 'min_data_in_leaf': 78, 'od_type': 'IncToDec', 'od_wait': 45}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:17:48,217] Trial 71 finished with value: 0.8708246029744382 and parameters: {'iterations': 673, 'learning_rate': 0.015200020163894004, 'depth': 10, 'l2_leaf_reg': 0.0002533732638549375, 'subsample': 0.7026999138200568, 'colsample_bylevel': 0.7905589554664947, 'min_data_in_leaf': 84, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:19:23,470] Trial 72 finished with value: 0.871773785425735 and parameters: {'iterations': 631, 'learning_rate': 0.009583061293290287, 'depth': 10, 'l2_leaf_reg': 0.0017911479622238773, 'subsample': 0.6866639757445989, 'colsample_bylevel': 0.6689327184011312, 'min_data_in_leaf': 78, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 53 with value: 0.8734575834740295.\n",
            "[I 2024-05-13 05:21:03,219] Trial 73 finished with value: 0.8735018721819152 and parameters: {'iterations': 589, 'learning_rate': 0.008285025386408901, 'depth': 10, 'l2_leaf_reg': 3.3103600600759615e-05, 'subsample': 0.7846151055617812, 'colsample_bylevel': 0.7531767838141986, 'min_data_in_leaf': 67, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:22:35,615] Trial 74 finished with value: 0.8714795083494193 and parameters: {'iterations': 580, 'learning_rate': 0.011676933953546863, 'depth': 10, 'l2_leaf_reg': 0.00010052655016671711, 'subsample': 0.7975362156103826, 'colsample_bylevel': 0.7351348367256603, 'min_data_in_leaf': 67, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:24:10,497] Trial 75 finished with value: 0.8718308523596768 and parameters: {'iterations': 604, 'learning_rate': 0.010062304964463456, 'depth': 10, 'l2_leaf_reg': 3.3366392932430034e-05, 'subsample': 0.7389472619163198, 'colsample_bylevel': 0.6922318433252471, 'min_data_in_leaf': 67, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:24:23,875] Trial 76 finished with value: 0.859005460731613 and parameters: {'iterations': 723, 'learning_rate': 0.017962312340627392, 'depth': 4, 'l2_leaf_reg': 4.027449044665425e-05, 'subsample': 0.6449532962663921, 'colsample_bylevel': 0.793129016348194, 'min_data_in_leaf': 80, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:26:00,602] Trial 77 finished with value: 0.8712365069206964 and parameters: {'iterations': 757, 'learning_rate': 0.014790587852554568, 'depth': 10, 'l2_leaf_reg': 5.638414257737035e-06, 'subsample': 0.7300148891755339, 'colsample_bylevel': 0.5503237697759282, 'min_data_in_leaf': 74, 'od_type': 'IncToDec', 'od_wait': 27}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:26:24,331] Trial 78 finished with value: 0.8615166722057293 and parameters: {'iterations': 528, 'learning_rate': 0.012809807139464677, 'depth': 7, 'l2_leaf_reg': 0.0004167899588675901, 'subsample': 0.7797132405212921, 'colsample_bylevel': 0.7646128469892778, 'min_data_in_leaf': 88, 'od_type': 'IncToDec', 'od_wait': 37}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:28:10,328] Trial 79 finished with value: 0.8710714911564809 and parameters: {'iterations': 636, 'learning_rate': 0.009100805116986644, 'depth': 10, 'l2_leaf_reg': 1.775201207423757e-05, 'subsample': 0.8278632409811209, 'colsample_bylevel': 0.7323826460314132, 'min_data_in_leaf': 56, 'od_type': 'Iter', 'od_wait': 45}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:29:35,435] Trial 80 finished with value: 0.8711083837916911 and parameters: {'iterations': 560, 'learning_rate': 0.020198750247526084, 'depth': 10, 'l2_leaf_reg': 2.2810309232682302e-06, 'subsample': 0.8874349270801094, 'colsample_bylevel': 0.6703602822806074, 'min_data_in_leaf': 71, 'od_type': 'IncToDec', 'od_wait': 42}. Best is trial 73 with value: 0.8735018721819152.\n",
            "[I 2024-05-13 05:31:42,550] Trial 81 finished with value: 0.8744742036842436 and parameters: {'iterations': 676, 'learning_rate': 0.00820045593623102, 'depth': 10, 'l2_leaf_reg': 2.023476463221885e-08, 'subsample': 0.6662417079137691, 'colsample_bylevel': 0.8904061304120032, 'min_data_in_leaf': 64, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:33:49,252] Trial 82 finished with value: 0.8735497811788845 and parameters: {'iterations': 684, 'learning_rate': 0.006702285460260953, 'depth': 10, 'l2_leaf_reg': 1.7264274833670155e-08, 'subsample': 0.6660091870413961, 'colsample_bylevel': 0.8945897642892757, 'min_data_in_leaf': 76, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:35:55,946] Trial 83 finished with value: 0.8710512031523852 and parameters: {'iterations': 682, 'learning_rate': 0.005908083713315099, 'depth': 10, 'l2_leaf_reg': 1.3622204573568243e-08, 'subsample': 0.6098518351012049, 'colsample_bylevel': 0.8895415864828019, 'min_data_in_leaf': 65, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:38:03,218] Trial 84 finished with value: 0.8707651070686528 and parameters: {'iterations': 708, 'learning_rate': 0.00489562452624361, 'depth': 10, 'l2_leaf_reg': 2.028412621903575e-08, 'subsample': 0.5584656393178388, 'colsample_bylevel': 0.8579595153256033, 'min_data_in_leaf': 76, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:40:33,431] Trial 85 finished with value: 0.8722982846141598 and parameters: {'iterations': 836, 'learning_rate': 0.006996465261519817, 'depth': 10, 'l2_leaf_reg': 6.29158554585526e-08, 'subsample': 0.655932445464271, 'colsample_bylevel': 0.8412039823500843, 'min_data_in_leaf': 69, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:43:00,136] Trial 86 finished with value: 0.8705770557170597 and parameters: {'iterations': 824, 'learning_rate': 0.0069060260482802175, 'depth': 10, 'l2_leaf_reg': 0.009846187837604263, 'subsample': 0.7016608886682469, 'colsample_bylevel': 0.8441635393113609, 'min_data_in_leaf': 82, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:45:49,568] Trial 87 finished with value: 0.8742195936303185 and parameters: {'iterations': 896, 'learning_rate': 0.010297210278756271, 'depth': 10, 'l2_leaf_reg': 8.105550784802746e-08, 'subsample': 0.6353793524246077, 'colsample_bylevel': 0.9094079379882756, 'min_data_in_leaf': 68, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:48:46,948] Trial 88 finished with value: 0.8717948001909802 and parameters: {'iterations': 877, 'learning_rate': 0.008268101299679061, 'depth': 10, 'l2_leaf_reg': 1.0767431689364113e-07, 'subsample': 0.6775832527870174, 'colsample_bylevel': 0.9764458199065958, 'min_data_in_leaf': 78, 'od_type': 'IncToDec', 'od_wait': 50}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:48:53,946] Trial 89 finished with value: 0.8427718186956927 and parameters: {'iterations': 300, 'learning_rate': 0.009790655786850823, 'depth': 5, 'l2_leaf_reg': 0.6475557045597993, 'subsample': 0.5716864526195844, 'colsample_bylevel': 0.9142758764260777, 'min_data_in_leaf': 62, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:51:13,074] Trial 90 finished with value: 0.8452829905573302 and parameters: {'iterations': 799, 'learning_rate': 0.001119633385786851, 'depth': 9, 'l2_leaf_reg': 3.6140756949194983e-07, 'subsample': 0.6169107823810183, 'colsample_bylevel': 0.935589418278166, 'min_data_in_leaf': 92, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:54:08,297] Trial 91 finished with value: 0.872895662873159 and parameters: {'iterations': 931, 'learning_rate': 0.008049595338173475, 'depth': 10, 'l2_leaf_reg': 5.992023492413559e-08, 'subsample': 0.649196429416753, 'colsample_bylevel': 0.8767050051542598, 'min_data_in_leaf': 69, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 81 with value: 0.8744742036842436.\n",
            "[I 2024-05-13 05:57:12,324] Trial 92 finished with value: 0.8753334016479707 and parameters: {'iterations': 987, 'learning_rate': 0.00794812040578884, 'depth': 10, 'l2_leaf_reg': 1.8797385861143014e-08, 'subsample': 0.7495072912757781, 'colsample_bylevel': 0.8787194065417225, 'min_data_in_leaf': 75, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:00:07,404] Trial 93 finished with value: 0.8727450785025839 and parameters: {'iterations': 958, 'learning_rate': 0.010796066770352417, 'depth': 10, 'l2_leaf_reg': 1.8575090473027834e-08, 'subsample': 0.7118018964707304, 'colsample_bylevel': 0.8775909264133831, 'min_data_in_leaf': 73, 'od_type': 'IncToDec', 'od_wait': 46}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:03:13,563] Trial 94 finished with value: 0.873220310073687 and parameters: {'iterations': 937, 'learning_rate': 0.007990832765118078, 'depth': 10, 'l2_leaf_reg': 3.511003298997297e-08, 'subsample': 0.6381008982716675, 'colsample_bylevel': 0.9726317590630825, 'min_data_in_leaf': 85, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:06:17,372] Trial 95 finished with value: 0.8718119556552544 and parameters: {'iterations': 961, 'learning_rate': 0.009042086835241296, 'depth': 10, 'l2_leaf_reg': 2.953548009501411e-08, 'subsample': 0.7501059413972107, 'colsample_bylevel': 0.9063216731611661, 'min_data_in_leaf': 84, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:09:06,742] Trial 96 finished with value: 0.8746920613631028 and parameters: {'iterations': 866, 'learning_rate': 0.012153740913186127, 'depth': 10, 'l2_leaf_reg': 1.4921287305461383e-08, 'subsample': 0.5876044578120675, 'colsample_bylevel': 0.9672291638019668, 'min_data_in_leaf': 79, 'od_type': 'IncToDec', 'od_wait': 49}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:11:34,590] Trial 97 finished with value: 0.8647024475439199 and parameters: {'iterations': 917, 'learning_rate': 0.011816030166763913, 'depth': 9, 'l2_leaf_reg': 0.15814905220155404, 'subsample': 0.5214214315472533, 'colsample_bylevel': 0.9676836295145516, 'min_data_in_leaf': 80, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:14:21,954] Trial 98 finished with value: 0.8727984407021442 and parameters: {'iterations': 864, 'learning_rate': 0.01695520851872875, 'depth': 10, 'l2_leaf_reg': 4.677766993310511e-08, 'subsample': 0.6295723565433005, 'colsample_bylevel': 0.9351045667711709, 'min_data_in_leaf': 86, 'od_type': 'IncToDec', 'od_wait': 47}. Best is trial 92 with value: 0.8753334016479707.\n",
            "[I 2024-05-13 06:14:44,707] Trial 99 finished with value: 0.8589784328438712 and parameters: {'iterations': 914, 'learning_rate': 0.013833108170559771, 'depth': 5, 'l2_leaf_reg': 2.0258061962728666e-07, 'subsample': 0.5964876248323308, 'colsample_bylevel': 0.9681884943692517, 'min_data_in_leaf': 76, 'od_type': 'IncToDec', 'od_wait': 48}. Best is trial 92 with value: 0.8753334016479707.\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0e43nDS4H4i",
        "outputId": "662e58fc-42e8-4344-8237-1974917cebd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8753334016479707"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdaw5rZmmL-D",
        "outputId": "c48e11a2-8597-4d14-8c8b-8c56e1fea0e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'iterations': 987,\n",
              " 'learning_rate': 0.00794812040578884,\n",
              " 'depth': 10,\n",
              " 'l2_leaf_reg': 1.8797385861143014e-08,\n",
              " 'subsample': 0.7495072912757781,\n",
              " 'colsample_bylevel': 0.8787194065417225,\n",
              " 'min_data_in_leaf': 75,\n",
              " 'od_type': 'IncToDec',\n",
              " 'od_wait': 47}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\SURYA B.S\\Documents\\customer-churn-prediction\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
            "[WinError 2] The system cannot find the file specified\n",
            "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
            "  warnings.warn(\n",
            "  File \"c:\\Users\\SURYA B.S\\Documents\\customer-churn-prediction\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
            "    cpu_info = subprocess.run(\n",
            "               ^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\SURYA B.S\\Documents\\customer-churn-prediction\\venv\\Lib\\subprocess.py\", line 548, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\SURYA B.S\\Documents\\customer-churn-prediction\\venv\\Lib\\subprocess.py\", line 1026, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "  File \"c:\\Users\\SURYA B.S\\Documents\\customer-churn-prediction\\venv\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
            "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        }
      ],
      "source": [
        "best_params = {'iterations': 987,\n",
        "            'learning_rate': 0.00794812040578884,\n",
        "            'depth': 10,\n",
        "            'l2_leaf_reg': 1.8797385861143014e-08,\n",
        "            'subsample': 0.7495072912757781,\n",
        "            'colsample_bylevel': 0.8787194065417225,\n",
        "            'min_data_in_leaf': 75,\n",
        "            'od_type': 'IncToDec',\n",
        "            'od_wait': 47}\n",
        "\n",
        "model = CatBoostClassifier(**best_params, silent=True)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "predicted = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.91      0.94      1063\n",
            "         1.0       0.92      0.97      0.94      1110\n",
            "\n",
            "    accuracy                           0.94      2173\n",
            "   macro avg       0.94      0.94      0.94      2173\n",
            "weighted avg       0.94      0.94      0.94      2173\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
